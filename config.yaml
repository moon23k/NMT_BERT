train:
  n_epochs: 10
  batch_size: 32
  max_len: 512
  clip: 1
  iters_to_accumulate: 4
  lr: 0.0005
  early_stop: 1
  patience: 3


model:
  mname: 'albert-base-v2'
  n_heads: 8
  n_layers: 3
  pff_dim: 512
  hidden_dim: 256
  dropout_ratio: 0.1